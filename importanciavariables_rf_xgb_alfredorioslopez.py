# -*- coding: utf-8 -*-
"""Importanciavariables_RF_XGB_AlfredoRiosLopez.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1y4CmNQCaDq_SeTGiD7-vmX1UwyMt0qIb

**Modelo con hiperparámetro random forest**
"""

import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import GridSearchCV, TimeSeriesSplit
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import matplotlib.pyplot as plt
import seaborn as sns

# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
# CARGA DE DATOS
# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
file_path = "/content/DatosTempHKObs__Finales.xlsx"
data = pd.read_excel(file_path)
data['Date'] = pd.to_datetime(data['Date'])

# Eliminar columnas no deseadas
cols_to_drop = ['Punto de rocio', 'Year', 'Month', 'Day']
data = data.drop(columns=[col for col in cols_to_drop if col in data.columns])

# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
# DIVISIÓN ENTRE TRAIN Y TEST
# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
train_data = data[data['Date'] < '2012-01-01']
test_data = data[data['Date'] >= '2012-01-01']

# Variables predictoras
features = ['Nubes (%)', 'Humedad (%)', 'Precipitacion (mm)', 'Presion (hPa)']
X_train = train_data[features]
X_test = test_data[features]

# Variables objetivo
targets = ['MaxTemp', 'MinTemp', 'MeanTemp']

# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
# OPTIMIZACIÓN DE HYPERPARÁMETROS
# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
tscv = TimeSeriesSplit(n_splits=3)
def tune_random_forest(X, y):
    param_grid = {
        'n_estimators': [100, 200],
        'max_depth': [15, 20],
        'min_samples_split': [2, 5],
        'min_samples_leaf': [1, 2],
        'max_features': ['sqrt', 'log2'],
        'bootstrap': [True, False]
    }

    rf = RandomForestRegressor(random_state=42)
    grid_search = GridSearchCV(rf, param_grid, cv=tscv, scoring='r2', n_jobs=2, verbose=1)
    grid_search.fit(X, y)

    print("Mejores parámetros encontrados:", grid_search.best_params_)
    return grid_search.best_estimator_

# Lista para guardar las métricas
metrics_summary = []

# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
# FUNCIÓN DE RANDOM FOREST + MÉTRICAS Y GRÁFICOS
# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
def evaluate_rf_model(y_col):
    y_train = train_data[y_col]
    y_test = test_data[y_col]

    print(f"\n🔍 Optimizando hiperparámetros para: {y_col}")
    rf = tune_random_forest(X_train, y_train)

    y_train_pred = rf.predict(X_train)
    y_test_pred = rf.predict(X_test)

    # MÉTRICAS
    def report_metrics(y_true, y_pred, label):
        r2 = r2_score(y_true, y_pred)
        mae = mean_absolute_error(y_true, y_pred)
        rmse = np.sqrt(mean_squared_error(y_true, y_pred))
        print(f"\n{label} - {y_col}")
        print(f"  R²:   {r2:.3f}")
        print(f"  MAE:  {mae:.3f}")
        print(f"  RMSE: {rmse:.3f}")
        return r2, mae, rmse

    r2_test, mae_test, rmse_test = report_metrics(y_test, y_test_pred, "Test")
    report_metrics(y_train, y_train_pred, "Train")

    # Guardar métricas
    metrics_summary.append({
        "Variable": y_col,
        "R2_Test": round(r2_test, 3),
        "MAE_Test": round(mae_test, 3),
        "RMSE_Test": round(rmse_test, 3)
    })

    # IMPORTANCIA DE VARIABLES
    importances = pd.Series(rf.feature_importances_, index=X_train.columns).sort_values()
    plt.figure(figsize=(8, 5))
    importances.plot(kind='barh', color='forestgreen')
    plt.title(f"Importancia de Variables - {y_col}")
    plt.xlabel("Importancia")
    plt.tight_layout()
    plt.show()

    # GRÁFICO: REAL VS PREDICHO (TEST)
    plt.figure(figsize=(10, 4))
    plt.plot(test_data['Date'], y_test.values, label="Real", color="steelblue")
    plt.plot(test_data['Date'], y_test_pred, label="Predicción", color="darkred")
    plt.fill_between(test_data['Date'], y_test_pred, y_test.values, color="gray", alpha=0.2, label="Error")
    plt.title(f"Predicción vs Real - {y_col}")
    plt.xlabel("Fecha")
    plt.ylabel("Valor")
    plt.legend()
    plt.tight_layout()
    plt.show()

    # GRÁFICO: ERRORES/RESIDUOS
    residuals = y_test.values - y_test_pred
    plt.figure(figsize=(8, 4))
    plt.plot(test_data['Date'], residuals, color='orange', label='Error')
    plt.axhline(0, color='black', linestyle='--')
    plt.title(f"Errores (Residuos) - {y_col}")
    plt.xlabel("Fecha")
    plt.ylabel("Error")
    plt.legend()
    plt.tight_layout()
    plt.show()

# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
# EVALUAR CADA VARIABLE OBJETIVO
# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
for target in targets:
    evaluate_rf_model(target)

# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
# TABLA FINAL DE MÉTRICAS
# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
df_metrics = pd.DataFrame(metrics_summary)
print("\n📊 Tabla resumen de métricas (Test):")
print(df_metrics.to_string(index=False))

# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
# MATRIZ DE CORRELACIÓN (OPCIONAL)
# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
plt.figure(figsize=(10, 8))
corr = data.drop(columns=['Date']).corr()
sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=".2f", square=True)
plt.title("Matriz de Correlación entre Variables")
plt.tight_layout()
plt.show()

"""**XGB con hiperparametros**

Comparativa MAE y MSE
"""

import pandas as pd
import numpy as np
import xgboost as xgb
from sklearn.model_selection import TimeSeriesSplit, GridSearchCV
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import matplotlib.pyplot as plt
import seaborn as sns

# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
# CARGA DE DATOS
# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
file_path = "/content/DatosTempHKObs__Finales.xlsx"
data = pd.read_excel(file_path)
data['Date'] = pd.to_datetime(data['Date'])

# Eliminar columnas no deseadas
cols_to_drop = ['Punto de rocio', 'Year', 'Month', 'Day']
data = data.drop(columns=[col for col in cols_to_drop if col in data.columns])

# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
# DIVISIÓN ENTRE TRAIN Y TEST
# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
train_data = data[data['Date'] < '2012-01-01']
test_data = data[data['Date'] >= '2012-01-01']

features = data.columns.difference(['Date', 'MaxTemp', 'MinTemp', 'MeanTemp'])
X_train = train_data[features]
X_test = test_data[features]

targets = ['MaxTemp', 'MinTemp', 'MeanTemp']
tscv = TimeSeriesSplit(n_splits=3)
metrics_summary = []

# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
# FUNCIÓN DE EVALUACIÓN XGBOOST
# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
def evaluate_xgboost_model(y_col, objective_name, scoring_metric):
    y_train = train_data[y_col]
    y_test = test_data[y_col]

    print(f"\n🔍 XGBoost ({objective_name}) para: {y_col}")

    model = xgb.XGBRegressor(objective=objective_name, n_jobs=-1, random_state=42)

    param_grid = {
        'max_depth': [3, 5],
        'learning_rate': [0.05, 0.1],
        'n_estimators': [100, 200],
        'subsample': [0.8, 1],
        'colsample_bytree': [0.8, 1]
    }

    grid_search = GridSearchCV(model, param_grid, cv=tscv, scoring=scoring_metric, verbose=0)
    grid_search.fit(X_train, y_train)

    best_model = grid_search.best_estimator_
    print("✅ Mejores parámetros:", grid_search.best_params_)

    y_train_pred = best_model.predict(X_train)
    y_test_pred = best_model.predict(X_test)

    # MÉTRICAS
    def report_metrics(y_true, y_pred, label):
        r2 = r2_score(y_true, y_pred)
        mae = mean_absolute_error(y_true, y_pred)
        rmse = np.sqrt(mean_squared_error(y_true, y_pred))
        print(f"\n {label} - {y_col} ({objective_name})")
        print(f"  R²:   {r2:.3f}")
        print(f"  MAE:  {mae:.3f}")
        print(f"  RMSE: {rmse:.3f}")
        return r2, mae, rmse

    r2_test, mae_test, rmse_test = report_metrics(y_test, y_test_pred, "Test")
    report_metrics(y_train, y_train_pred, "Train")

    # Guardar métricas
    metrics_summary.append({
        "Variable": y_col,
        "Pérdida": objective_name,
        "R2_Test": round(r2_test, 3),
        "MAE_Test": round(mae_test, 3),
        "RMSE_Test": round(rmse_test, 3)
    })

# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
# EVALUAR TODAS LAS VARIABLES (MAE Y MSE)
# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
for target in targets:
    evaluate_xgboost_model(target, objective_name='reg:absoluteerror', scoring_metric='neg_mean_absolute_error')
    evaluate_xgboost_model(target, objective_name='reg:squarederror', scoring_metric='neg_mean_squared_error')

# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
# TABLA FINAL DE MÉTRICAS
# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
df_metrics = pd.DataFrame(metrics_summary)
print("\n📊 Tabla resumen de métricas (Test):")
print(df_metrics.to_string(index=False))

# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
# CORRELACIÓN DE VARIABLES
# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
plt.figure(figsize=(10, 8))
corr = data.drop(columns=['Date']).corr()
sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=".2f", square=True)
plt.title("Matriz de Correlación entre Variables")
plt.tight_layout()
plt.show()

"""Importancia de las variables"""

import pandas as pd
import numpy as np
import xgboost as xgb
from sklearn.model_selection import TimeSeriesSplit, GridSearchCV
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import matplotlib.pyplot as plt
import seaborn as sns

# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
# CARGA DE DATOS
# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
file_path = "/content/DatosTempHKObs__Finales.xlsx"
data = pd.read_excel(file_path)
data['Date'] = pd.to_datetime(data['Date'])

# Eliminar columnas no deseadas
cols_to_drop = ['Punto de rocio', 'Year', 'Month', 'Day']
data = data.drop(columns=[col for col in cols_to_drop if col in data.columns])

# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
# DIVISIÓN ENTRE TRAIN Y TEST
# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
train_data = data[data['Date'] < '2012-01-01']
test_data = data[data['Date'] >= '2012-01-01']

features = data.columns.difference(['Date', 'MaxTemp', 'MinTemp', 'MeanTemp'])
X_train = train_data[features]
X_test = test_data[features]

targets = ['MaxTemp', 'MinTemp', 'MeanTemp']

# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
# OPTIMIZACIÓN Y EVALUACIÓN XGBOOST
# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
tscv = TimeSeriesSplit(n_splits=3)
metrics_summary = []

def evaluate_xgboost_model(y_col):
    y_train = train_data[y_col]
    y_test = test_data[y_col]

    print(f"\n🔍 Optimizando XGBoost para: {y_col}")

    model = xgb.XGBRegressor(objective='reg:absoluteerror', n_jobs=-1, random_state=42)

    param_grid = {
      'max_depth': [3, 5, 7, 9],
      'learning_rate': [0.01, 0.05, 0.1, 0.2],
      'n_estimators': [100, 200, 300],
      'subsample': [ 0.8, 1],
      'colsample_bytree': [ 0.8, 1]
    }

    grid_search = GridSearchCV(model, param_grid, cv=tscv, scoring='r2', verbose=1)
    grid_search.fit(X_train, y_train)

    best_model = grid_search.best_estimator_
    print("✅ Mejores parámetros:", grid_search.best_params_)

    y_train_pred = best_model.predict(X_train)
    y_test_pred = best_model.predict(X_test)

    # MÉTRICAS
    def report_metrics(y_true, y_pred, label):
        r2 = r2_score(y_true, y_pred)
        mae = mean_absolute_error(y_true, y_pred)
        rmse = np.sqrt(mean_squared_error(y_true, y_pred))
        print(f"\n {label} - {y_col}")
        print(f"  R²:   {r2:.3f}")
        print(f"  MAE:  {mae:.3f}")
        print(f"  RMSE: {rmse:.3f}")
        return r2, mae, rmse

    r2_test, mae_test, rmse_test = report_metrics(y_test, y_test_pred, "Test")
    report_metrics(y_train, y_train_pred, "Train")

    # Guardar métricas
    metrics_summary.append({
        "Variable": y_col,
        "R2_Test": round(r2_test, 3),
        "MAE_Test": round(mae_test, 3),
        "RMSE_Test": round(rmse_test, 3)
    })

    # IMPORTANCIA DE VARIABLES
    importances = pd.Series(best_model.feature_importances_, index=X_train.columns).sort_values()
    plt.figure(figsize=(8, 5))
    importances.plot(kind='barh', color='forestgreen')
    plt.title(f"Importancia de Variables - {y_col}")
    plt.xlabel("Importancia")
    plt.tight_layout()
    plt.show()

    # REAL VS PREDICHO
    plt.figure(figsize=(10, 4))
    plt.plot(test_data['Date'], y_test.values, label="Real", color="steelblue")
    plt.plot(test_data['Date'], y_test_pred, label="Predicción", color="darkred")
    plt.fill_between(test_data['Date'], y_test_pred, y_test.values, color="gray", alpha=0.2, label="Error")
    plt.title(f"Predicción vs Real - {y_col}")
    plt.xlabel("Fecha")
    plt.ylabel("Valor")
    plt.legend()
    plt.tight_layout()
    plt.show()

# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
# EVALUAR TODAS LAS VARIABLES
# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
for target in targets:
    evaluate_xgboost_model(target)

# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
# TABLA FINAL DE MÉTRICAS
# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
df_metrics = pd.DataFrame(metrics_summary)
print("\n📊 Tabla resumen de métricas (Test):")
print(df_metrics.to_string(index=False))

# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
# CORRELACIÓN DE VARIABLES
# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
plt.figure(figsize=(10, 8))
corr = data.drop(columns=['Date']).corr()
sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=".2f", square=True)
plt.title("Matriz de Correlación entre Variables")
plt.tight_layout()
plt.show()

"""**Comparativa de los modelos**"""

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

# Cargar datos desde Excel
ruta_excel = '/content/TablaDeMetricas.xlsx'  # ← Asegúrate de que esta ruta sea válida
hoja = 'Hoja1'
df = pd.read_excel(ruta_excel, sheet_name=hoja, index_col=0)

# Extraer métricas y modelos
metricas = df.index.tolist()     # ['R2', 'MAE', 'RMSE']
modelos = df.columns.tolist()    # ['Modelo A', 'Modelo B', 'Modelo C']
valores = [df[modelo].values for modelo in modelos]  # lista de listas: una por modelo

# Posiciones y ancho
x = np.arange(len(metricas))  # una barra por métrica
ancho = 0.25

# Graficar
fig, ax = plt.subplots(figsize=(10, 6))

for i, (modelo, valores_modelo) in enumerate(zip(modelos, valores)):
    ax.bar(x + i * ancho, valores_modelo, width=ancho, label=modelo)

# Personalización
ax.set_xlabel('Métrica')
ax.set_ylabel('Valor')
ax.set_title('Comparación de Métricas por Modelo')
ax.set_xticks(x + ancho)
ax.set_xticklabels(metricas)
ax.legend(title='Modelo')


plt.tight_layout()
plt.show()